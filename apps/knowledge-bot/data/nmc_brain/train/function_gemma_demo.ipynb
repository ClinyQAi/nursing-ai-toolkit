{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Nursing FunctionGemma Demo\n",
                "\n",
                "This notebook demonstrates the **Nursing FunctionGemma** model's ability to convert natural language into structured function calls.\n",
                "\n",
                "**Available Tools:**\n",
                "- `record_vitals(systolic, diastolic, heart_rate, temp_c)` - Record patient vitals\n",
                "- `administer_medication(drug_name, dose, route)` - Log medication administration\n",
                "- `search_nmc_standards(query)` - Search NMC guidance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q -U transformers peft torch accelerate bitsandbytes huggingface_hub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from huggingface_hub import login\n",
                "login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
                "from peft import PeftModel\n",
                "\n",
                "# Model IDs\n",
                "BASE_MODEL_ID = \"google/medgemma-4b-it\"\n",
                "ADAPTER_ID = \"NurseCitizenDeveloper/nursing-function-gemma\"\n",
                "\n",
                "print(\"Loading base model...\")\n",
                "bnb_config = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_compute_dtype=torch.bfloat16\n",
                ")\n",
                "\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    BASE_MODEL_ID,\n",
                "    quantization_config=bnb_config,\n",
                "    device_map=\"auto\",\n",
                "    trust_remote_code=True\n",
                ")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "print(f\"Loading FunctionGemma adapter from: {ADAPTER_ID}\")\n",
                "model = PeftModel.from_pretrained(model, ADAPTER_ID)\n",
                "print(\"‚úÖ Model loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def call_function_gemma(user_input):\n",
                "    \"\"\"Send a request to FunctionGemma and get the function call output.\"\"\"\n",
                "    \n",
                "    tools_prompt = \"\"\"You are a clinical AI agent. You have access to the following tools:\n",
                "- record_vitals(systolic, diastolic, heart_rate, temp_c)\n",
                "- administer_medication(drug_name, dose, route)\n",
                "- search_nmc_standards(query)\n",
                "If the user's request requires a tool, output the function call XML.\"\"\"\n",
                "\n",
                "    prompt = f\"<start_of_turn>user\\n{tools_prompt}\\n\\n{user_input}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
                "    \n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=100,\n",
                "            do_sample=False,  # Deterministic for function calls\n",
                "            temperature=0.1,\n",
                "            eos_token_id=tokenizer.eos_token_id\n",
                "        )\n",
                "    \n",
                "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    \n",
                "    # Extract just the model's response\n",
                "    if \"<start_of_turn>model\" in response:\n",
                "        response = response.split(\"<start_of_turn>model\")[-1].strip()\n",
                "    \n",
                "    return response"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ Test Cases\n",
                "\n",
                "Let's test the model with different nursing scenarios!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test 1: Record Vitals\n",
                "print(\"=\" * 50)\n",
                "print(\"TEST 1: Recording Vitals\")\n",
                "print(\"=\" * 50)\n",
                "user_input = \"Patient's BP is 120/80, pulse 72, temp 37.2\"\n",
                "print(f\"Input: {user_input}\")\n",
                "print(f\"Output: {call_function_gemma(user_input)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test 2: Medication Administration\n",
                "print(\"=\" * 50)\n",
                "print(\"TEST 2: Medication Administration\")\n",
                "print(\"=\" * 50)\n",
                "user_input = \"I've given Paracetamol 1g orally\"\n",
                "print(f\"Input: {user_input}\")\n",
                "print(f\"Output: {call_function_gemma(user_input)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test 3: NMC Standards Search\n",
                "print(\"=\" * 50)\n",
                "print(\"TEST 3: NMC Standards Search\")\n",
                "print(\"=\" * 50)\n",
                "user_input = \"What does the NMC say about confidentiality?\"\n",
                "print(f\"Input: {user_input}\")\n",
                "print(f\"Output: {call_function_gemma(user_input)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test 4: IV Medication\n",
                "print(\"=\" * 50)\n",
                "print(\"TEST 4: IV Medication\")\n",
                "print(\"=\" * 50)\n",
                "user_input = \"Administered Morphine 10mg IV\"\n",
                "print(f\"Input: {user_input}\")\n",
                "print(f\"Output: {call_function_gemma(user_input)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Interactive Demo\n",
                "\n",
                "Try your own inputs below!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interactive: Enter your own input\n",
                "your_input = \"Just took obs: Heart rate 88, Blood pressure 140 over 90, temp 38.1\"\n",
                "print(f\"Your Input: {your_input}\")\n",
                "print(f\"\\nFunctionGemma Output:\\n{call_function_gemma(your_input)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Success Criteria\n",
                "\n",
                "The model should output structured function calls like:\n",
                "```\n",
                "<function_call>record_vitals(systolic=120, diastolic=80, heart_rate=72, temp_c=37.2)</function_call>\n",
                "```\n",
                "\n",
                "or\n",
                "\n",
                "```\n",
                "<function_call>administer_medication(drug_name='Paracetamol', dose='1g', route='PO')</function_call>\n",
                "```\n",
                "\n",
                "---\n",
                "\n",
                "**Developed by Lincoln Gombedza | Nursing Citizen Development** ü©∫"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}