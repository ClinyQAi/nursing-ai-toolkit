{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üè• MedGemma Function Calling with In-Context Learning\n",
                "\n",
                "**No fine-tuning!** Just clever prompting with examples.\n",
                "\n",
                "This tests if base MedGemma can do function calling when given good examples in the prompt."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install -q transformers torch accelerate bitsandbytes huggingface_hub"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from huggingface_hub import login\n",
                "login()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "import torch.distributed as dist\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
                "\n",
                "try:\n",
                "    if not dist.is_initialized():\n",
                "        dist.init_process_group(backend=\"gloo\", init_method=\"file:///tmp/icl_test\", rank=0, world_size=1)\n",
                "except: pass\n",
                "\n",
                "MODEL_ID = \"google/medgemma-4b-it\"\n",
                "\n",
                "print(f\"Loading BASE MedGemma (no adapter)...\")\n",
                "bnb_config = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_compute_dtype=torch.bfloat16\n",
                ")\n",
                "\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_ID,\n",
                "    quantization_config=bnb_config,\n",
                "    device_map={\"\": 0},\n",
                "    trust_remote_code=True\n",
                ")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "print(\"‚úÖ Base MedGemma loaded (NO adapter)!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def function_call_icl(user_input):\n",
                "    \"\"\"\n",
                "    Use in-context learning with few-shot examples.\n",
                "    \"\"\"\n",
                "    prompt = f\"\"\"<start_of_turn>user\n",
                "You are a clinical documentation AI. Convert natural language clinical notes into structured function calls.\n",
                "\n",
                "## Available Functions:\n",
                "1. record_vitals(systolic, diastolic, heart_rate, temp_c) - Record patient vital signs\n",
                "2. administer_medication(drug_name, dose, route) - Log medication administration\n",
                "3. search_nmc_standards(query) - Search NMC nursing guidelines\n",
                "\n",
                "## Examples:\n",
                "\n",
                "Input: \"BP is 120/80, pulse 72, temp 37.2\"\n",
                "Output: record_vitals(systolic=120, diastolic=80, heart_rate=72, temp_c=37.2)\n",
                "\n",
                "Input: \"Gave Paracetamol 1g orally\"\n",
                "Output: administer_medication(drug_name=\"Paracetamol\", dose=\"1g\", route=\"PO\")\n",
                "\n",
                "Input: \"Blood pressure 145/95, heart rate 88\"\n",
                "Output: record_vitals(systolic=145, diastolic=95, heart_rate=88)\n",
                "\n",
                "Input: \"Administered Morphine 5mg IV\"\n",
                "Output: administer_medication(drug_name=\"Morphine\", dose=\"5mg\", route=\"IV\")\n",
                "\n",
                "Input: \"What does NMC say about confidentiality?\"\n",
                "Output: search_nmc_standards(query=\"confidentiality\")\n",
                "\n",
                "## Your Task:\n",
                "Convert the following input into a function call. Output ONLY the function call, nothing else.\n",
                "\n",
                "Input: \"{user_input}\"\n",
                "Output:<end_of_turn>\n",
                "<start_of_turn>model\n",
                "\"\"\"\n",
                "    \n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=60,\n",
                "            do_sample=False,\n",
                "            eos_token_id=tokenizer.eos_token_id,\n",
                "            pad_token_id=tokenizer.eos_token_id\n",
                "        )\n",
                "    \n",
                "    # Decode only new tokens\n",
                "    input_length = inputs['input_ids'].shape[1]\n",
                "    new_tokens = outputs[0][input_length:]\n",
                "    response = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
                "    \n",
                "    # Clean up - take first line only\n",
                "    if '\\n' in response:\n",
                "        response = response.split('\\n')[0]\n",
                "    \n",
                "    return response"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Test cases\n",
                "test_cases = [\n",
                "    \"BP is 110/70, pulse 68\",\n",
                "    \"Patient's BP 130/85, heart rate 78, temperature 36.9\",\n",
                "    \"Gave Paracetamol 500mg orally\",\n",
                "    \"Administered Morphine 10mg IV\",\n",
                "    \"What does NMC say about duty of candour?\",\n",
                "    \"Heart rate 92, blood pressure 140 over 90\",\n",
                "    \"IV Flucloxacillin 1g given\",\n",
                "    \"Find NMC guidance on delegation\"\n",
                "]\n",
                "\n",
                "print(\"üß™ Testing BASE MedGemma with In-Context Learning\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "for test in test_cases:\n",
                "    result = function_call_icl(test)\n",
                "    print(f\"\\nInput: {test}\")\n",
                "    print(f\"Output: {result}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üìä Evaluation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import json\n",
                "import re\n",
                "\n",
                "# Load eval dataset if available\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive', force_remount=False)\n",
                "    \n",
                "    with open('/content/drive/MyDrive/nmc_brain/data/function_eval_dataset.json', 'r') as f:\n",
                "        eval_data = json.load(f)\n",
                "    \n",
                "    print(f\"\\nüìä Running evaluation on {len(eval_data)} test cases...\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    correct = 0\n",
                "    func_name_correct = 0\n",
                "    has_values = 0\n",
                "    \n",
                "    for i, item in enumerate(eval_data[:20]):  # First 20 for speed\n",
                "        predicted = function_call_icl(item['input'])\n",
                "        expected = item['expected']\n",
                "        \n",
                "        # Check function name\n",
                "        exp_func = expected.split('(')[0]\n",
                "        if exp_func in predicted:\n",
                "            func_name_correct += 1\n",
                "        \n",
                "        # Check for values\n",
                "        if re.search(r'=\\d+', predicted) or re.search(r'=\"[^\"]+\"', predicted):\n",
                "            has_values += 1\n",
                "        \n",
                "        # Exact match (normalized)\n",
                "        if re.sub(r'\\s+', '', expected.lower()) == re.sub(r'\\s+', '', predicted.lower()):\n",
                "            correct += 1\n",
                "        \n",
                "        if i < 5:  # Show first 5\n",
                "            status = \"‚úÖ\" if exp_func in predicted else \"‚ùå\"\n",
                "            print(f\"\\n{status} Example {i+1}:\")\n",
                "            print(f\"   Input: {item['input'][:50]}...\")\n",
                "            print(f\"   Expected: {expected}\")\n",
                "            print(f\"   Got: {predicted}\")\n",
                "    \n",
                "    n = min(20, len(eval_data))\n",
                "    print(f\"\\n\" + \"=\"*60)\n",
                "    print(f\"üìä RESULTS (first {n} examples):\")\n",
                "    print(f\"   Function Name Accuracy: {func_name_correct/n*100:.1f}%\")\n",
                "    print(f\"   Value Extraction Rate: {has_values/n*100:.1f}%\")\n",
                "    print(f\"   Exact Match Accuracy: {correct/n*100:.1f}%\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Could not run full evaluation: {e}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}