name: AI News Scanner for Nursing Education

on:
  # Run every Monday at 9:00 AM UTC (Adjust to your timezone)
  schedule:
    - cron: '0 9 * * 1'
  # Allow manual trigger
  workflow_dispatch:

jobs:
  scan-ai-news:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install feedparser requests beautifulsoup4

      - name: Scan AI News Sources
        id: scan
        run: |
          python << 'EOF'
          import feedparser
          import requests
          from datetime import datetime, timedelta
          import json

          # Define AI news sources (RSS feeds)
          FEEDS = {
              "Google AI Blog": "https://blog.google/technology/ai/rss/",
              "OpenAI Blog": "https://openai.com/blog/rss.xml",
              "DeepMind Blog": "https://deepmind.google/blog/rss.xml",
              "Healthcare AI News": "https://www.healthcareitnews.com/taxonomy/term/702/feed",
          }

          # Keywords to filter for healthcare/nursing relevance
          KEYWORDS = [
              "nursing", "healthcare", "clinical", "medical", "patient",
              "diagnosis", "education", "learning", "gemini", "multimodal"
          ]

          # Get articles from the last 7 days
          one_week_ago = datetime.utcnow() - timedelta(days=7)
          
          relevant_articles = []

          for source_name, feed_url in FEEDS.items():
              try:
                  feed = feedparser.parse(feed_url)
                  for entry in feed.entries[:10]:  # Check latest 10 entries
                      # Check if article is recent
                      pub_date = datetime(*entry.published_parsed[:6])
                      if pub_date < one_week_ago:
                          continue
                      
                      # Check for relevant keywords
                      text = f"{entry.title} {entry.get('summary', '')}".lower()
                      if any(keyword in text for keyword in KEYWORDS):
                          relevant_articles.append({
                              "source": source_name,
                              "title": entry.title,
                              "link": entry.link,
                              "published": pub_date.strftime("%Y-%m-%d"),
                              "summary": entry.get('summary', 'No summary available')[:200]
                          })
              except Exception as e:
                  print(f"Error fetching {source_name}: {e}")

          # Save results
          if relevant_articles:
              with open('ai_news_digest.json', 'w') as f:
                  json.dump(relevant_articles, f, indent=2)
              print(f"Found {len(relevant_articles)} relevant articles")
              print("HAS_NEWS=true")
          else:
              print("No relevant news found this week")
              print("HAS_NEWS=false")
          EOF

      - name: Create Issue with News Digest
        if: steps.scan.outputs.HAS_NEWS == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const articles = JSON.parse(fs.readFileSync('ai_news_digest.json', 'utf8'));
            
            let body = '## ü§ñ Weekly AI News Digest for Nursing Education\n\n';
            body += `**Scan Date**: ${new Date().toISOString().split('T')[0]}\n\n`;
            body += `Found **${articles.length}** relevant articles this week:\n\n`;
            body += '---\n\n';
            
            articles.forEach((article, index) => {
              body += `### ${index + 1}. ${article.title}\n`;
              body += `**Source**: ${article.source} | **Date**: ${article.published}\n\n`;
              body += `${article.summary}...\n\n`;
              body += `üîó [Read More](${article.link})\n\n`;
              body += '---\n\n';
            });
            
            body += '\n\n### üìù Next Steps\n';
            body += '- Review these articles for relevance\n';
            body += '- Consider updating relevant sections in the toolkit\n';
            body += '- Close this issue once reviewed\n';
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üì∞ AI News Digest - ${new Date().toISOString().split('T')[0]}`,
              body: body,
              labels: ['ai-news', 'content-update']
            });

      - name: Send Email Notification (Optional)
        if: steps.scan.outputs.HAS_NEWS == 'true'
        run: |
          echo "To enable email notifications, add SendGrid API key to secrets"
          echo "For now, check the GitHub Issues tab for the news digest"
